{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Знакомство-с-данными\" data-toc-modified-id=\"Знакомство-с-данными-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Знакомство с данными</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Downsampling\" data-toc-modified-id=\"Downsampling-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Downsampling</a></span></li><li><span><a href=\"#Очистка-признаков\" data-toc-modified-id=\"Очистка-признаков-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Очистка признаков</a></span></li><li><span><a href=\"#Токенизация-текстов\" data-toc-modified-id=\"Токенизация-текстов-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Токенизация текстов</a></span></li><li><span><a href=\"#Создание-эмбеддингов\" data-toc-modified-id=\"Создание-эмбеддингов-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Создание эмбеддингов</a></span></li><li><span><a href=\"#Разделение-на-выборки\" data-toc-modified-id=\"Разделение-на-выборки-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Разделение на выборки</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Baseline\" data-toc-modified-id=\"Baseline-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Baseline</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#LightGBMClassifier\" data-toc-modified-id=\"LightGBMClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>LightGBMClassifier</a></span></li></ul></li><li><span><a href=\"#Анализ-результатов\" data-toc-modified-id=\"Анализ-результатов-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Анализ результатов</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию человеку. \n",
    "\n",
    "Наша задача - обучить модель классифицировать комментарии на позитивные и негативные. \n",
    "\n",
    "**Описание данных**\n",
    "* В нашем распоряжении набор текстов с разметкой по их токсичности.\n",
    "* Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import torch\n",
    "import transformers\n",
    "import xgboost as xgb\n",
    "\n",
    "from io import BytesIO\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    cross_validate\n",
    ")\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import notebook\n",
    "from transformers import AutoModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import pipeline\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RS = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean        394.073221\n",
       "std         590.720282\n",
       "min           6.000000\n",
       "25%          96.000000\n",
       "50%         205.000000\n",
       "75%         435.000000\n",
       "max        5000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем мы планируем использовать BERT для токенизации и создания эмбеддингов, поэтому сразу удалим тексты, длинной более 512 символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[df['text'].str.len()<=512, 'text']\n",
    "y = df.loc[df['text'].str.len()<=512, 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((126535,), (126535,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.887841\n",
       "1    0.112159\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    "\n",
    "1. В наших данных представлено 159571 наблюдений, каждое из которых имеет текст (комментарий с сайта магазина \"Викишоп\") и целевую метку, описывающую токсичность текста (1 - токсичный, 0 - нетоксичный).\n",
    "2. Средняя длина текста 394 символа, медиана при этом 205 символов - сказывается наличие выбросов (самый длинный комментарий - 5000 символов).\n",
    "3. В данных имеет место дисбаланс классов - токсичных комментариев всего 10%\n",
    "3. Мы сразу же отбросили все тексты с длиной более 512 символов, так как на следующих этапах планируем использовать модель BERT для токенизации и создания эмбеддингов. \n",
    "    * В результате потеряли около 20% данных.\n",
    "    * Дисбаланс классов сохранился, 11% целевого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "Для более качественного обучения моделей классификации выполним *dowwnsampling*, уменьшив количество нетоксичных текстов до количества токсичных (получим соотношение классов 1:1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(X, y, fraction):\n",
    "    X_zeros = X[y == 0]\n",
    "    X_ones = X[y == 1]\n",
    "    y_zeros = y[y == 0]\n",
    "    y_ones = y[y == 1]\n",
    "\n",
    "    X_downsampled = pd.concat(\n",
    "        [X_zeros.sample(frac=fraction, random_state=RS)] + [X_ones])\n",
    "    y_downsampled = pd.concat(\n",
    "        [y_zeros.sample(frac=fraction, random_state=RS)] + [y_ones])\n",
    "    \n",
    "    X_downsampled, y_downsampled = shuffle(\n",
    "        X_downsampled, y_downsampled, random_state=RS)\n",
    "    \n",
    "    return X_downsampled, y_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля остающихся нетоксичных комментариев 0.13 - выбрана таким образом, чтобы достичь соотношения классов 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28797,), (28797,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = downsample(X, y, 0.13)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка признаков\n",
    "\n",
    "Поскольку комментарии это сырой текст, набранный пользователями  в интернете, нам необходимо его немного почистить.\n",
    "\n",
    "Функция `preprocess_text` принимает на вход текст комментария и возвращает очищенный комментарий:\n",
    "* Удаляет все цифры и знаки пунктуации, оставляя только апостроф, т.к. он важен для английских слов;\n",
    "* Удаляет одинокие символы (например, артикли);\n",
    "* Удаляет множественные пробелы, которые могли появиться на предыдущих шагах очистки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(comment):\n",
    "    # удаление цифр и пунктуации, кроме апострофа\n",
    "    comment = re.sub(\"[^a-zA-Z']\", \" \", comment)\n",
    "\n",
    "    # удаление одиноких символов\n",
    "    comment = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', comment)\n",
    "\n",
    "    # удаление множественных пробелов\n",
    "    comment = re.sub(r'\\s+', ' ', comment)\n",
    "\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28797.000000\n",
       "mean       155.189499\n",
       "std        117.687178\n",
       "min          1.000000\n",
       "25%         59.000000\n",
       "50%        121.000000\n",
       "75%        226.000000\n",
       "max        502.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.apply(preprocess_text)\n",
    "X.apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Наш корпус текстов выглядит уже намного лучше:\n",
    "* Во-первых, их стало меньше - 28797 текстов;\n",
    "* Во-вторых теперь они более сбалансированные по длине - среднее 155, медиана 121;\n",
    "* В-третьих, очищены от ненужных символов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация текстов\n",
    "\n",
    "Для токенизации наших комментариев, а также для создания эмбеддингов мы будем использовать модель BERT, специально обученную для задач классификации текстов по токсичности. Модель называется `toxic-bert` и создана командой **The Conversation AI**, исследовательской инициативой компаний Jigsaw и Google. Модель создавалась для поддержания здоровой атмосферы в онлайн-беседах и обучалась на корпусе английской википедии, а также на комментариях пользователей из интернета.\n",
    "\n",
    "[Ссылка на репозиторий unitary/toxic-bert](https://huggingface.co/unitary/toxic-bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20.5 s\n",
      "Wall time: 23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28797,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "tokenized = X.apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(tokenized.apply(len))\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28797, 178)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание эмбеддингов\n",
    "\n",
    "Для создания эмбеддингов будем использовать весь наш сбалансированный датасет (28797 текстов).\n",
    "Используем всё ту же предобученную на токсичных текстах модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как эмбеддинги создаются довольно долго (около 3-х часов на домашней машине), для удобства ревьювинга архив с дампом эмбеддингов загружен на облачное хранилище, откуда и подгружается при наличии интернета и доступности ссылки.\n",
    "\n",
    "В следующей ячейке этот подход реализован в виде ветвящегося кода:\n",
    "* Если ссылка актвна (код ответа 200), забираем по ней npz-файл (85 Мб), это архив numpy, он имеет структуру словаря, поэтому для дальнейшей работы его необходимо распарсить в список массивов;\n",
    "    * После загрузки файла проверяем количество батчей, количество эмбеддингов в батче и длину каждого эмбеддинга.\n",
    "* Если ссылка недоступна (код ответа 404), тогда создаём эмбеддинги заново (143 батча по 200 текстов в каждом) и по завершении сохраняем их на диск в файл `embeddings_for_toxic_comments`\n",
    "* В случае других ошибок возвращается сообщение с просьбой проверить интернет-соединение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Npz-file with embeddings found, unpacking in progress.\n",
      "\n",
      "Проверим размерность загруженного файла с эмбеддингами:\n",
      "\n",
      "    Количество батчей: 143\n",
      "    Количество текстов в одном батче: 200\n",
      "    Длина эмбеддинга одного текста: 768\n",
      "\n",
      "CPU times: total: 984 ms\n",
      "Wall time: 7.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = requests.get('https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/2oUi72Fa6uBgsQ')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Npz-file with embeddings found, unpacking in progress.\\n\")\n",
    "    embeddings_zip = np.load(BytesIO(response.content)) \n",
    "    embeddings = []\n",
    "    for key, arr in embeddings_zip.items():\n",
    "        embeddings.append(arr)\n",
    "    print('Проверим размерность загруженного файла с эмбеддингами:')\n",
    "    print(\"\"\"\n",
    "    Количество батчей: {0}\n",
    "    Количество текстов в одном батче: {1}\n",
    "    Длина эмбеддинга одного текста: {2}\\n\"\"\".format(len(embeddings),\n",
    "                                                  len(embeddings[0]),\n",
    "                                                  len(embeddings[0][0])\n",
    "                                                  )\n",
    "         )\n",
    "    \n",
    "elif response.status_code == 404:\n",
    "    print(\"The file was not found with embeddings by the link, proceed to create embeddings again.\")\n",
    "    batch_size = 200\n",
    "    embeddings = []\n",
    "    for batch_number in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "            start = batch_size*batch_number\n",
    "            end = batch_size*(batch_number + 1)\n",
    "\n",
    "            batch = torch.LongTensor(padded[start:end]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[start:end])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "    np.savez(\"embeddings_for_toxic_comments\", *embeddings)\n",
    "\n",
    "else:\n",
    "    print('Check your internet-connection!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на выборки\n",
    "\n",
    "При создании эмбеддингов мы брали тексты из выборки батчами по 200 штук, поэтому получилось некоторое расхождение в количестве наблюдений между X и y. Просто обрежем наши целевые метки **y** до длины вектора признаков. *Таким образом мы терям 197 наблюдений.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28600, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate(embeddings)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28600,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[:X.shape[0]].reset_index(drop=True).values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем исходный набор на выборки, под тест отводим 20% данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22880, 768), (5720, 768))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RS)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение моделей будем проводить с помощью фреймворка **Optuna**, задача которого оптимальным образом подбирать гиперпараметры для любых моделей.\n",
    "\n",
    "* Для контроля обобщающей способности моделей и переобучения используем кросс-валидацию с делением обучающей выборки на 5 фолдов;\n",
    "* Результаты работы каждой модели сохраняем в датафрейм, индексами которого являются метрики F1 (среднее гармонической точности и полноты). Здесь сохраняем сразу и F1 с обучающей выборки (с кросс-валидации) и с тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=['f1_train', 'f1_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `optuna_search` принимает на вход функцию, которую необходимо оптимизировать, количество испытаний в исследовании и имя исследования. Внутри:\n",
    "1. Создаем экземпляр класса `study` из модуля Optuna, задаём направление оптимизации функции (так как у нас F1, то её максимизируем для повышения качества модели);\n",
    "2. Запускам собственно процесс оптимизации созданного исследования (`study`) с заданным количеством испытаний (`trial`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_search(obj_func, n_trials, study_name='unnamed'):\n",
    "    study = optuna.create_study(direction='maximize', study_name=study_name)\n",
    "    study.optimize(obj_func, n_trials=n_trials)\n",
    "    \n",
    "    print(f\"\\tBest value (F1-score): {study.best_value:.5f}\")\n",
    "    print(f\"\\tBest params:\")\n",
    "\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"\\t\\t{key}: {value}\")\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `metric_fixer` необходима для фиксации результатов в вышеописанный датафрейм `results`:\n",
    "1. Принимает на вход оптимизированный объект класса `optuna.Study` и строковое имя модели, которую мы оптимизировали;\n",
    "2. Из словаря берёт чистый объект модели (лог.регрессию, случайный лес или LightGBM-классификатор);\n",
    "3. Инициализирует модель с параметрами, которые были выбраны как наилучшие в процессе исследования Оптуной;\n",
    "4. Обучает модель на полной обучающей выборке;\n",
    "5. Считает метрику качества F1 на тестовой выборке и записывает в датафрейм `results`. Туда же записывает и наилучшее значение F1, полученной Оптуной в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fixer(study: optuna.Study, model):\n",
    "    models_dict = {\n",
    "        'lr': LogisticRegression(random_state=RS),\n",
    "        'rf': RandomForestClassifier(),\n",
    "        'lgbm': LGBMClassifier()\n",
    "    } \n",
    "    \n",
    "    model = models_dict.get(model).set_params(**study.best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    score_train = study.best_value\n",
    "    score_test = f1_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    results[type(model).__name__] = [score_train, score_test]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "В качестве базовой точки для обучения, а также проверки на адекватность наших следующих моделей используем думми-классификатор из библиотеки `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика для думми-классификатора: 0.47616\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='stratified', random_state=RS)\n",
    "dummy.fit(X_train, y_train)\n",
    "pred = dummy.predict(X_test)\n",
    "score_train = f1_score(y_train, dummy.predict(X_train))\n",
    "score_test = f1_score(y_test, pred)\n",
    "results['DummyClassifier'] = [score_train, score_test]\n",
    "print('F1 метрика для думми-классификатора: {0}'.format(round(score_test, 5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial: optuna.Trial):\n",
    "    logreg_c = trial.suggest_float('C', 1e-10, 1e10, log=True)\n",
    "    tol = trial.suggest_float('tol', 1e-5, 1e-1, log=True)\n",
    "    model = LogisticRegression(C=logreg_c)\n",
    "    scores = cross_validate(model, X_train, y_train, cv=kf, scoring=\"f1\")\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 14:12:29,494]\u001b[0m A new study created in memory with name: LogReg\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:12:40,130]\u001b[0m Trial 0 finished with value: 0.9730424048666219 and parameters: {'C': 1846.6599842808337, 'tol': 0.012417885322843202}. Best is trial 0 with value: 0.9730424048666219.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:12:42,389]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'C': 1.0521786231743486e-09, 'tol': 0.00082776632964173}. Best is trial 0 with value: 0.9730424048666219.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:12:52,167]\u001b[0m Trial 2 finished with value: 0.9735213611913253 and parameters: {'C': 1022633.7377555621, 'tol': 0.0002099004260738631}. Best is trial 2 with value: 0.9735213611913253.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:12:57,565]\u001b[0m Trial 3 finished with value: 0.9767756520585076 and parameters: {'C': 0.0012171590035575995, 'tol': 1.4106294375622711e-05}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:13:07,929]\u001b[0m Trial 4 finished with value: 0.9760801218441719 and parameters: {'C': 0.06914939976068218, 'tol': 0.0007902118758857721}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:13:18,057]\u001b[0m Trial 5 finished with value: 0.972871105832516 and parameters: {'C': 48.544923166561475, 'tol': 0.00017015503976968859}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:13:28,100]\u001b[0m Trial 6 finished with value: 0.9727741385847091 and parameters: {'C': 659872635.1066104, 'tol': 1.292962093962516e-05}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:13:38,821]\u001b[0m Trial 7 finished with value: 0.9733501659441461 and parameters: {'C': 1365.6905854822917, 'tol': 2.0646416234899516e-05}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:13:48,851]\u001b[0m Trial 8 finished with value: 0.9732146862433059 and parameters: {'C': 2564.3322402525423, 'tol': 0.05529983190145239}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 14:13:58,964]\u001b[0m Trial 9 finished with value: 0.9766245577259897 and parameters: {'C': 0.02582872965986302, 'tol': 0.0002352431468468047}. Best is trial 3 with value: 0.9767756520585076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (F1-score): 0.97678\n",
      "\tBest params:\n",
      "\t\tC: 0.0012171590035575995\n",
      "\t\ttol: 1.4106294375622711e-05\n",
      "CPU times: total: 8min 27s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_study = optuna_search(objective_lr, 10, 'LogReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.02 s\n",
      "Wall time: 1.23 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.495070</td>\n",
       "      <td>0.976776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.476157</td>\n",
       "      <td>0.969912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DummyClassifier  LogisticRegression\n",
       "f1_train         0.495070            0.976776\n",
       "f1_test          0.476157            0.969912"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metric_fixer(lr_study, 'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial: optuna.Trial):\n",
    "    params = {\n",
    "    'random_state': RS,\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "    'max_depth': trial.suggest_int('max_depth', 1, 32, log=True),\n",
    "    'max_features': trial.suggest_int('max_features', 3, 27),\n",
    "#     'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 9, step=3),\n",
    "#     'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n",
    "#     'criterion': trial.suggest_categorical('criterion', [\"gini\", \"entropy\"])\n",
    "          }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    scores = cross_validate(model, X_train, y_train, cv=kf, scoring=\"f1\", n_jobs=-1)\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 10:18:05,352]\u001b[0m A new study created in memory with name: RandomForest\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 10:18:30,067]\u001b[0m Trial 0 finished with value: 0.9735079457855292 and parameters: {'n_estimators': 318, 'max_depth': 1, 'max_features': 8}. Best is trial 0 with value: 0.9735079457855292.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 10:19:04,407]\u001b[0m Trial 1 finished with value: 0.9738434065437961 and parameters: {'n_estimators': 440, 'max_depth': 1, 'max_features': 8}. Best is trial 1 with value: 0.9738434065437961.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 10:24:17,794]\u001b[0m Trial 2 finished with value: 0.9764032500086544 and parameters: {'n_estimators': 308, 'max_depth': 8, 'max_features': 18}. Best is trial 2 with value: 0.9764032500086544.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 10:32:17,662]\u001b[0m Trial 3 finished with value: 0.9763235819106102 and parameters: {'n_estimators': 359, 'max_depth': 7, 'max_features': 27}. Best is trial 2 with value: 0.9764032500086544.\u001b[0m\n",
      "\u001b[32m[I 2022-06-17 10:43:10,648]\u001b[0m Trial 4 finished with value: 0.9760294305104832 and parameters: {'n_estimators': 254, 'max_depth': 19, 'max_features': 25}. Best is trial 2 with value: 0.9764032500086544.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (F1-score): 0.97640\n",
      "\tBest params:\n",
      "\t\tn_estimators: 308\n",
      "\t\tmax_depth: 8\n",
      "\t\tmax_features: 18\n",
      "CPU times: user 25min, sys: 93.9 ms, total: 25min\n",
      "Wall time: 25min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_study = optuna_search(objective_rf, 10, 'RandomForest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение результатов исследования на локальный диск для удобства продолжения оптимизации в случае перезагрузки ядра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(rf_study, \"rf_study.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка результатов из дампа на локальном диске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_study = joblib.load(\"rf_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 35s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.495070</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.976487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.476157</td>\n",
       "      <td>0.969912</td>\n",
       "      <td>0.969761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DummyClassifier  LogisticRegression  RandomForestClassifier\n",
       "f1_train         0.495070            0.976776                0.976487\n",
       "f1_test          0.476157            0.969912                0.969761"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metric_fixer(rf_study, 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial: optuna.Trial):\n",
    "    params = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "#         \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "#         \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "#         \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "#         \"feature_fraction\": trial.suggest_float(\n",
    "#             \"feature_fraction\", 0.2, 0.95, step=0.1),\n",
    "#         \"max_bin\": trial.suggest_int(\"max_bin\", 30, 300)\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    scores = cross_validate(model, X_train, y_train, cv=kf, scoring=\"f1\", n_jobs=None)\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-17 10:45:21,330]\u001b[0m A new study created in memory with name: LGBM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_study = optuna_search(objective_lgbm, 10, 'LGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(lgbm_study, \"lgbm_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_study = joblib.load(\"lgbm_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "CPU times: total: 2min 34s\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.495070</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.976487</td>\n",
       "      <td>0.976141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.476157</td>\n",
       "      <td>0.969912</td>\n",
       "      <td>0.969761</td>\n",
       "      <td>0.971530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DummyClassifier  LogisticRegression  RandomForestClassifier  \\\n",
       "f1_train         0.495070            0.976776                0.976487   \n",
       "f1_test          0.476157            0.969912                0.969761   \n",
       "\n",
       "          LGBMClassifier  \n",
       "f1_train        0.976141  \n",
       "f1_test         0.971530  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "metric_fixer(lgbm_study, 'lgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.49507</td>\n",
       "      <td>0.97678</td>\n",
       "      <td>0.97649</td>\n",
       "      <td>0.97614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.47616</td>\n",
       "      <td>0.96991</td>\n",
       "      <td>0.96976</td>\n",
       "      <td>0.97153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DummyClassifier  LogisticRegression  RandomForestClassifier  \\\n",
       "f1_train          0.49507             0.97678                 0.97649   \n",
       "f1_test           0.47616             0.96991                 0.96976   \n",
       "\n",
       "          LGBMClassifier  \n",
       "f1_train         0.97614  \n",
       "f1_test          0.97153  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(results, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все модели показали себя очень хорошо, **метрика F1 не опускалась ниже 0.96** ни на обучающей, ни на тестовой выборке;\n",
    "* Вероятнее всего это связано с хорошей подготовкой данных перед обучением, включая использование очень хорошей и специфичной к токсичности предобученной модели от команды **Conversation AI**;\n",
    "* Учитывая скорость обучения и скорость инференса, мы рекомендуем заказчику использовать логистическую регрессию. Она уступает модели бустинга лишь в 3-м знаке после запятой, зато работает значительно быстрее;\n",
    "* К сожалению, из-за специфики работы BERT'а невозможно после обучения визуализировать наиболее важные слова/фразы/предложения, на которые опирались модели в решении задачи классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом проекте мы использовали датасет из 159 тысяч текстовых комментариев из магазина \"Викишоп\", размеченных по токсичности (1/0) чтобы обучить модель классификации. В процессе работы:\n",
    "1. Ознакомились с данными и базовыми описательными статистиками;\n",
    "2. В связи с дисбалансом классов (90/10) уменьшили количество нетоксичных текстов, случайно выбрав 13% из них, т.о. достигнув соотношения токсичных и нетоксичных текстов 50/50;\n",
    "3. Перед токенизацией и векторизацией текстов выполнили очистку от знаков пунктуации, цифр, нелатинских букв, одиноких символов и множественных пробелов;\n",
    "4. Токенизацию и векторизацию текстов выполнили с помощью предобученной на большом корпусе модифицированной BERT-модели (*unitary/toxic-bert* в репозитории HuggingFace). Эта модель была обучена при поддержке Google и высокоспецифична к выявлению токсичность в онлайн-беседах;\n",
    "5. В данном проекте мы обучали классификации 3 модели из разных классов: логистическая регрессия, случайный лес и бустинг LightGBM. Все модели достигли прекрасных показателей качества с метрикой **F1 более 0.96 на тестовой выборке**.\n",
    "6. Учитывая такие факторы, как скорость обучения и предсказания модели, а также её сложность, **мы рекомендуем заказчику (\"Викишоп\") использовать в данном случае логистическую регрессию**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 663,
    "start_time": "2022-06-17T09:13:11.551Z"
   },
   {
    "duration": 5653,
    "start_time": "2022-06-17T09:13:22.919Z"
   },
   {
    "duration": 3918,
    "start_time": "2022-06-17T09:13:30.862Z"
   },
   {
    "duration": 2406,
    "start_time": "2022-06-17T09:14:03.041Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-17T09:14:21.935Z"
   },
   {
    "duration": 2287,
    "start_time": "2022-06-17T09:14:30.051Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-17T09:14:32.340Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-17T09:14:32.354Z"
   },
   {
    "duration": 72,
    "start_time": "2022-06-17T09:14:32.391Z"
   },
   {
    "duration": 228,
    "start_time": "2022-06-17T09:14:32.465Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T09:14:32.694Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-17T09:14:32.700Z"
   },
   {
    "duration": 54629,
    "start_time": "2022-06-17T09:14:37.163Z"
   },
   {
    "duration": 54459,
    "start_time": "2022-06-17T09:17:05.107Z"
   },
   {
    "duration": 53347,
    "start_time": "2022-06-17T09:18:41.806Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T09:25:07.384Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-17T09:25:08.134Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T09:25:09.258Z"
   },
   {
    "duration": 700,
    "start_time": "2022-06-17T09:25:09.685Z"
   },
   {
    "duration": 22226,
    "start_time": "2022-06-17T09:37:41.213Z"
   },
   {
    "duration": 680,
    "start_time": "2022-06-17T09:39:14.168Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T09:39:18.961Z"
   },
   {
    "duration": 2683,
    "start_time": "2022-06-17T09:46:47.484Z"
   },
   {
    "duration": 40,
    "start_time": "2022-06-17T09:47:29.183Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T09:47:30.037Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-17T09:52:34.641Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T09:52:34.985Z"
   },
   {
    "duration": 330,
    "start_time": "2022-06-17T10:02:05.079Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-17T10:02:26.723Z"
   },
   {
    "duration": 4467,
    "start_time": "2022-06-17T10:02:32.135Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T10:02:36.604Z"
   },
   {
    "duration": 756,
    "start_time": "2022-06-17T10:02:36.612Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-17T10:02:37.370Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-17T10:02:37.379Z"
   },
   {
    "duration": 65,
    "start_time": "2022-06-17T10:02:37.401Z"
   },
   {
    "duration": 199,
    "start_time": "2022-06-17T10:02:37.468Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T10:02:37.669Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-17T10:02:37.674Z"
   },
   {
    "duration": 56435,
    "start_time": "2022-06-17T10:02:37.692Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T10:03:34.129Z"
   },
   {
    "duration": 54,
    "start_time": "2022-06-17T10:03:34.136Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-17T10:03:34.192Z"
   },
   {
    "duration": 813,
    "start_time": "2022-06-17T10:03:34.197Z"
   },
   {
    "duration": 20690,
    "start_time": "2022-06-17T10:03:35.012Z"
   },
   {
    "duration": 546,
    "start_time": "2022-06-17T10:03:55.703Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-17T10:03:56.250Z"
   },
   {
    "duration": 9295,
    "start_time": "2022-06-17T10:03:56.267Z"
   },
   {
    "duration": 2528,
    "start_time": "2022-06-17T10:04:05.569Z"
   },
   {
    "duration": 1667,
    "start_time": "2022-06-17T10:04:08.099Z"
   },
   {
    "duration": 1657,
    "start_time": "2022-06-17T10:04:09.769Z"
   },
   {
    "duration": 62,
    "start_time": "2022-06-17T10:04:11.428Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-17T10:04:11.492Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-17T10:04:11.496Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-17T10:04:11.523Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-17T10:04:11.535Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-17T10:04:11.546Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-17T10:04:43.889Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T10:06:44.345Z"
   },
   {
    "duration": 285819,
    "start_time": "2022-06-17T10:06:47.051Z"
   },
   {
    "duration": 187,
    "start_time": "2022-06-17T10:11:32.873Z"
   },
   {
    "duration": 55,
    "start_time": "2022-06-17T10:15:11.743Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T10:15:23.775Z"
   },
   {
    "duration": 10764,
    "start_time": "2022-06-17T10:15:26.290Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-17T10:17:06.724Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T10:17:16.738Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-17T10:17:28.700Z"
   },
   {
    "duration": 10601,
    "start_time": "2022-06-17T10:17:38.953Z"
   },
   {
    "duration": 95,
    "start_time": "2022-06-17T10:17:49.559Z"
   },
   {
    "duration": 1505301,
    "start_time": "2022-06-17T10:18:05.350Z"
   },
   {
    "duration": 78893,
    "start_time": "2022-06-17T10:43:10.653Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T10:45:18.942Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.388px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
